{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featured-based Approach: Text Embedding + Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../Data/team_train.json'\n",
    "with open(train_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "dev_path = '../Data/team_dev.json'\n",
    "with open(dev_path, 'r', encoding='utf-8') as file:\n",
    "    data_dev = json.load(file)\n",
    "\n",
    "test_path = '../Data/team_test.json'\n",
    "with open(test_path, 'r', encoding='utf-8') as file:\n",
    "    data_test = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_dataframe(data, has_label=True):\n",
    "    ID, post1, post2, Class = [], [], [], []\n",
    "\n",
    "    for i in data:\n",
    "        ID.append(i[0])\n",
    "        post1.append(i[1])\n",
    "        post2.append(i[2])\n",
    "        if has_label:\n",
    "            Class.append(i[3])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'ID': ID,\n",
    "        'post1': post1,\n",
    "        'post2': post2\n",
    "    })\n",
    "\n",
    "    if has_label:\n",
    "        df['class'] = Class\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = build_dataframe(data, has_label=True)\n",
    "df_dev = build_dataframe(data_dev, has_label=True)\n",
    "df_test = build_dataframe(data_test, has_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data CLeaning\n",
    "import re\n",
    "def clean_text(text):\n",
    "    # Eliminate unnecessary spaces and newlines, inserting a period where the newline originally occurred.\n",
    "    cleaned_text = re.sub(r'\\s*\\n+\\s*', '。', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Text Embedding 003\n",
    "Get embeddings for training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='your OpenAI API key')\n",
    "\n",
    "def build_embeddings(data, output_path=None, has_label=True, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generate embeddings for the input data and return as a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list\n",
    "        Input data in the format (ID, post1, post2, class) or (ID, post1, post2).\n",
    "    output_path : str or None\n",
    "        If provided, saves the resulting DataFrame as a CSV file.\n",
    "    has_label : bool\n",
    "        True if the data includes class labels (train/dev), False for test set.\n",
    "    model : str\n",
    "        The name of the embedding model to use.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        A DataFrame containing the original data along with generated embeddings.\n",
    "    \"\"\"\n",
    "    IDs, posts1, posts2, labels = [], [], [], []\n",
    "    embeds1, embeds2 = [], []\n",
    "    embeddings_concat, embeddings_dot, embeddings_mul = [], [], []\n",
    "\n",
    "    for instance in data:\n",
    "        ID, p1, p2 = instance[0], instance[1], instance[2]\n",
    "        IDs.append(ID)\n",
    "        posts1.append(p1)\n",
    "        posts2.append(p2)\n",
    "        if has_label:\n",
    "            labels.append(instance[3])\n",
    "\n",
    "        # 產生 embedding\n",
    "        e1 = client.embeddings.create(input=clean_text(str(p1)), model=model).data[0].embedding\n",
    "        e2 = client.embeddings.create(input=clean_text(str(p2)), model=model).data[0].embedding\n",
    "        embeds1.append(e1)\n",
    "        embeds2.append(e2)\n",
    "\n",
    "        # 三種組合方式\n",
    "        embeddings_concat.append(np.concatenate([e1, e2]))\n",
    "\n",
    "    # 建立 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"ID\": IDs,\n",
    "        \"post1\": posts1,\n",
    "        \"post2\": posts2,\n",
    "        \"embeds1\": embeds1,\n",
    "        \"embeds2\": embeds2,\n",
    "        \"embeddings_concat\": embeddings_concat,\n",
    "    })\n",
    "\n",
    "    if has_label:\n",
    "        df[\"class\"] = labels\n",
    "\n",
    "    # 輸出 CSV\n",
    "    if output_path:\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = build_embeddings(data, output_path=\"../Data/train_embedding.csv\", has_label=True)\n",
    "df_dev   = build_embeddings(data_dev, output_path=\"../Data/dev_embedding.csv\", has_label=True)\n",
    "df_test  = build_embeddings(data_test, output_path=\"../Data/test_embedding.csv\", has_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat_train = np.array(df_train['embeddings_concat'])\n",
    "y_train = np.array(df_train['class'])\n",
    "\n",
    "X_concat_dev = np.array(df_dev['embeddings_concat'])\n",
    "y_dev = np.array(df_dev['class'])\n",
    "\n",
    "X_concat_test = np.array(df_test['embeddings_concat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用拼接后的嵌入训练分类器\n",
    "#X_train_concat, X_test_concat, y_train_concat, y_test_concat = train_test_split(X_concat, y, test_size=0.2, random_state=42)\n",
    "train_shuffle, y_shuffle = shuffle(X_concat_train, y_train, random_state=42)\n",
    "clf_concat = RandomForestClassifier()\n",
    "# 超參數調優\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_concat, param_grid=param_grid, cv=KFold(n_splits=5, shuffle=True), n_jobs=-1, verbose=2)\n",
    "grid_search.fit(train_shuffle, y_shuffle)\n",
    "\n",
    "# 最佳模型\n",
    "best_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred_train = clf_concat.predict(X_concat_train)\n",
    "print(\"Training:\\n\", classification_report(df_train['class'], y_pred_train))\n",
    "# Validation\n",
    "y_pred_dev = clf_concat.predict(X_concat_dev)\n",
    "print(\"Validation:\\n\", classification_report(df_dev['class'], y_pred_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../Result/predicted_results_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "# save testing result and submit to Kaggle\n",
    "y_pred_concat = clf_concat.predict(X_concat_test)\n",
    "test_data = pd.DataFrame()\n",
    "test_data['y_pred'] = y_pred_concat\n",
    "test_data.index = df_test['ID']\n",
    "\n",
    "# save as .csv\n",
    "output_file = '../Result/RF_predicted.csv'\n",
    "test_data.to_csv(output_file)\n",
    "\n",
    "print(f'Results saved to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
